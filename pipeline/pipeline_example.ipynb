{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example ML Pipeline Interactive Notebook\n",
        "This notebook demonstrates running the example Python scripts from `pipeline/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Imported from `pipeline.zip` example*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow Overview\n",
        "# What This Script Does\n",
        "\n",
        "1. **Phase 2 — Data Collection**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m data_ingest.omni_cli file data/raw/users.csv --redact-pii --save\n",
        "     ```\n",
        "\n",
        "   - You can edit this line if your data source is different (e.g. `\"sql …\"` or `\"rest …\"`).\n",
        "\n",
        "2. **Phase 3 — Data Preparation**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m ml_pipeline.prepare --outlier iqr --scaler standard\n",
        "     ```\n",
        "\n",
        "   - Default choices: IQR outlier detection, StandardScaler, median/mode imputation, no balancing.\n",
        "   - Checks that `data/interim/clean.parquet` and `data/processed/scaled.parquet` are produced.\n",
        "\n",
        "3. **Phase 4 — EDA (Core)**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m Data_Analysis.EDA --mode all --target is_churn --profile\n",
        "     ```\n",
        "\n",
        "   - Generates univariate, bivariate, multivariate stats + plots, and an optional HTML profile.\n",
        "\n",
        "4. **Phase 4D — EDA (Advanced)**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m Data_Analysis.EDA_advance\n",
        "     ```\n",
        "\n",
        "   - Provides deeper analyses (mutual information, leakage sniff, TS decor, etc.).\n",
        "\n",
        "5. **Phase 4½ — Probabilistic Analysis**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m data_analysis.probabilistic_analysis --impute_method mice --target is_churn\n",
        "     ```\n",
        "\n",
        "   - You can add `--do_pit`, `--do_quantile`, or `--do_copula` if desired.\n",
        "\n",
        "6. **Phase 4½ — Feature Selection**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m Feature_Selection.feature_select --data data/processed/scaled.parquet --target is_churn --nzv_threshold 1e-5 --corr_threshold 0.95 --mi_quantile 0.10\n",
        "     ```\n",
        "\n",
        "   - Outputs `data/processed/selected.parquet` and `reports/feature/feature_audit.json`.\n",
        "\n",
        "7. **Phase 5 — Feature Engineering**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m Feature_Engineering.feature_engineering \\\n",
        "       --data data/processed/selected.parquet \\\n",
        "       --target is_churn \\\n",
        "       --numeric_scaler robust \\\n",
        "       --numeric_power yeo \\\n",
        "       --log_cols revenue \\\n",
        "       --quantile_bins age:4 \\\n",
        "       --polynomial_degree 2 \\\n",
        "       --rare_threshold 0.01 \\\n",
        "       --cat_encoding target \\\n",
        "       --text_vectorizer tfidf \\\n",
        "       --text_cols review \\\n",
        "       --datetime_cols last_login \\\n",
        "       --cyclical_cols hour:24 \\\n",
        "       --date_delta_cols signup_date:today \\\n",
        "       --aggregations customer_id:amount_mean,amount_sum \\\n",
        "       --drop_nzv \\\n",
        "       --corr_threshold 0.95 \\\n",
        "       --mi_quantile 0.10\n",
        "     ```\n",
        "\n",
        "   - Outputs `models/preprocessor.joblib`, `models/preprocessor.json` (SHA), plus\n",
        "     `reports/feature/feature_audit.json` and `reports/feature/feature_shape.txt`.\n",
        "\n",
        "8. **Phase 5½ — Split & Baseline**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m Data_Cleaning.split_and_baseline --target is_churn --seed 42 --stratify\n",
        "     ```\n",
        "\n",
        "   - Creates `data/splits/{train.parquet, val.parquet, test.parquet}`,\n",
        "     `data/splits/split_manifest.json`, and `reports/baseline/baseline_metrics.json`,\n",
        "     and snapshots `models/preprocessor_manifest.json`.\n",
        "\n",
        "9. **Phase 6 — Train + Tune**\n",
        "\n",
        "   - Runs\n",
        "\n",
        "     ```bash\n",
        "     python -m model.train\n",
        "     ```\n",
        "\n",
        "   - Consumes splits and preprocessor, produces `models/model.pkl`, `models/model_card.md`, and training metrics in `reports/metrics/`.\n",
        "\n",
        "10. **Phase 7 — Evaluate**\n",
        "\n",
        "    - Runs\n",
        "\n",
        "      ```bash\n",
        "      python -m model.evaluate\n",
        "      ```\n",
        "\n",
        "    - Consumes `data/splits/test.parquet` and `models/model.pkl`;\n",
        "      produces `reports/metrics/test_metrics.json` and `reports/metrics/roc_curve.csv`.\n",
        "\n",
        "11. **Phase 8 — Package → ONNX**\n",
        "\n",
        "    - Runs\n",
        "\n",
        "      ```bash\n",
        "      python -m model.package --model models/model.pkl\n",
        "      ```\n",
        "\n",
        "    - Exports `artefacts/model.onnx` (if implemented).\n",
        "\n",
        "12. **Phase 9 — Deploy (Optional)**\n",
        "\n",
        "    - If `deploy/push_to_registry.sh` exists, runs it. Otherwise, logs “SKIP”.\n",
        "\n",
        "## How to Use\n",
        "\n",
        "1. **Dry‑Run (Data Diagnostics + EDA + Probabilistic + Feature Selection)**\n",
        "   This mode will _only_ run diagnostics and analysis on your existing interim dataset (`data/interim/clean.parquet`) and then exit.\n",
        "\n",
        "   ```bash\n",
        "   python run_pipeline.py --dry-run\n",
        "   ```\n",
        "\n",
        "   - **Data Diagnostics** (missing values, imbalance, skewness, outliers)\n",
        "   - **Core EDA** → `python -m Data_Analysis.EDA --mode all --target is_churn`\n",
        "   - **Advanced EDA** → `python -m Data_Analysis.EDA_advance`\n",
        "   - **Probabilistic Analysis** → `python -m data_analysis.probabilistic_analysis`\n",
        "   - **Feature Selection** → `python -m Feature_Selection.feature_select`\n",
        "\n",
        "   > After these steps, the script prints a message and exits without running the rest of the pipeline.\n",
        "\n",
        "2. **Full Pipeline (End‑to‑End)**\n",
        "   This mode executes every phase in sequence:\n",
        "\n",
        "   1. **Phase 2 – Data Collection**\n",
        "\n",
        "      ```bash\n",
        "      python -m data_ingest.omni_cli file data/raw/users.csv --redact-pii --save\n",
        "      ```\n",
        "\n",
        "   2. **Phase 3 – Data Preparation**\n",
        "\n",
        "      ```bash\n",
        "      python -m ml_pipeline.prepare --outlier iqr --scaler standard --target is_churn\n",
        "      ```\n",
        "\n",
        "      (Add `--knn` or `--balance smote` if you modify `PREP_DEFAULT_ARGS` to `True`.)\n",
        "\n",
        "   3. **Phase 4 – Core EDA**\n",
        "\n",
        "      ```bash\n",
        "      python -m Data_Analysis.EDA --mode all --target is_churn\n",
        "      ```\n",
        "\n",
        "   4. **Phase 4D – Advanced EDA**\n",
        "\n",
        "      ```bash\n",
        "      python -m Data_Analysis.EDA_advance\n",
        "      ```\n",
        "\n",
        "   5. **Phase 4½ – Probabilistic Analysis**\n",
        "\n",
        "      ```bash\n",
        "      python -m data_analysis.probabilistic_analysis\n",
        "      ```\n",
        "\n",
        "   6. **Phase 4½ – Feature Selection**\n",
        "\n",
        "      ```bash\n",
        "      python -m Feature_Selection.feature_select --nzv_threshold 1e-5 --corr_threshold 0.95 --mi_quantile 0.1\n",
        "      ```\n",
        "\n",
        "   7. **Phase 5 – Feature Engineering**\n",
        "\n",
        "      ```bash\n",
        "      python -m Feature_Engineering.feature_engineering \\\n",
        "        --data data/processed/selected.parquet \\\n",
        "        --target is_churn \\\n",
        "        --numeric_scaler robust \\\n",
        "        --numeric_power yeo \\\n",
        "        --log_cols revenue \\\n",
        "        --quantile_bins age:4 \\\n",
        "        --polynomial_degree 2 \\\n",
        "        --rare_threshold 0.01 \\\n",
        "        --cat_encoding target \\\n",
        "        --text_vectorizer tfidf \\\n",
        "        --text_cols review \\\n",
        "        --datetime_cols last_login \\\n",
        "        --cyclical_cols hour:24 \\\n",
        "        --date_delta_cols signup_date:2023-01-01 \\\n",
        "        --aggregations customer_id:amount_mean,amount_sum \\\n",
        "        --drop_nzv \\\n",
        "        --corr_threshold 0.95 \\\n",
        "        --mi_quantile 0.1\n",
        "      ```\n",
        "\n",
        "   8. **Phase 5½ – Split & Baseline**\n",
        "\n",
        "      ```bash\n",
        "      python -m Data_Cleaning.split_and_baseline --target is_churn --seed 42 --stratify\n",
        "      ```\n",
        "\n",
        "   9. **Phase 6 – Model Training & Tuning**\n",
        "\n",
        "      ```bash\n",
        "      python -m model.train\n",
        "      ```\n",
        "\n",
        "      (Add any flags by editing `TRAIN_DEFAULT_ARGS` at top of this script.)\n",
        "\n",
        "3. **Phase 7 – Evaluation**\n",
        "\n",
        "   ```bash\n",
        "   python -m model.evaluate\n",
        "   ```\n",
        "\n",
        "4. **Phase 8 – Packaging**\n",
        "\n",
        "   ```bash\n",
        "   python -m model.package\n",
        "   ```\n",
        "\n",
        "5. **Phase 9 – Deployment**\n",
        "\n",
        "   ```bash\n",
        "   bash deploy/push_to_registry.sh\n",
        "   ```\n",
        "\n",
        "> Because **`run_pipeline.py`** no longer references `params.yaml`, you can either edit the hard‑coded defaults at the very top of `run_pipeline.py` (e.g. change `TARGET_COLUMN`, adjust `OMNI_CLI_DEFAULT_ARGS`, switch to SMOTE, etc.) or simply let it run with those values as‑is.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of Key Points\n",
        "\n",
        "- **No `params.yaml` dependency**—all defaults live in `run_pipeline.py`.\n",
        "- **Dry‑Run mode** (`--dry-run`)\n",
        "  • Loads `data/interim/clean.parquet` → runs data diagnostics (missingness, imbalance, skew, outliers).\n",
        "  • Runs core EDA + advanced EDA via Python modules (no need for manual notebook).\n",
        "  • Runs probabilistic analysis.\n",
        "  • Runs feature selection.\n",
        "  • Then exits.\n",
        "- **Full Pipeline** (no flags)\n",
        "  • Invokes each phase in order via shell commands—data ingestion → prep → EDA → prob analysis → feature selection → feature engineering → split & baseline → train → evaluate → package → deploy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run `ML_Flow.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run \"pipeline/ML_Flow.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run `ML_pipeline.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run \"pipeline/ML_pipeline.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run `ml_3.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run \"pipeline/ml_3.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run `ml_flow2.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run \"pipeline/ml_flow2.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run `run_pipeline.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "Exception",
          "evalue": "File `'pipeline/run_pipeline.py'` not found.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/magics/execution.py:716\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 716\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/utils/path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
            "\u001b[0;31mOSError\u001b[0m: File `'pipeline/run_pipeline.py'` not found.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline/run_pipeline.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/magics/execution.py:727\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    726\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
            "\u001b[0;31mException\u001b[0m: File `'pipeline/run_pipeline.py'` not found."
          ]
        }
      ],
      "source": [
        "%run \"pipeline/run_pipeline.py\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
