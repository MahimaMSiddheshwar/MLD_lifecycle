# params.yaml ─ Parameter file for entire MLDLC pipeline

# ────────────────────── PHASE-2 · DATA COLLECTION ─────────────────────────────
collect:
  args: "--source local --format csv" # Example: update based on CLI of omni_cli

# ────────────────────── PHASE-3 · DATA PREPARATION ─────────────────────────────
prepare:
  args: "--clean --impute --scale"
  max_missing_frac_drop: 0.9
  numeric_impute_methods:
    - mean
    - median
    - knn
    - mice
    - random
  categorical_impute_methods:
    - mode
    - constant
    - random
  missingness_test:
    - littles_test
    - logistic_missingness

# ────────────────────── SHARED PARAMS ACROSS STAGES ────────────────────────────
target: "target_column_name" # Replace with your dataset’s target column

# ────────────────────── PHASE-4½ · PROBABILISTIC ANALYSIS ───────────────────────
probabilistic:
  impute_method: "knn" # method to use before prob. analysis (if any missing values)
  do_pit: true # whether to apply Probability Integral Transform
  do_quantile: true # include quantile binning and KL-divergence
  do_copula: false # turn on for copula-based dependence tests

# ────────────────────── PHASE-4½ · FEATURE SELECTION ────────────────────────────
feature_selection:
  args: "--auto --threshold=0.01"
  method: "mutual_info" # Options: mutual_info, f_classif, chi2, boruta, etc.
  correlation_threshold: 0.95
  variance_threshold: 0.01
  max_features: 150

# ────────────────────── PHASE-4½ · SPLIT & BASELINE ─────────────────────────────
split:
  seed: 42
  stratify: true
  oversample: false
  val_size: 0.15
  test_size: 0.15

# ────────────────────── PHASE-5 · FEATURE ENGINEERING ───────────────────────────
feature_engineering:
  args: "--auto-construct --add-polynomials"
  interaction_depth: 2
  add_lags: false
  top_k_interactions: 25
  groupwise_aggs: false

# ────────────────────── PHASE-6 · TRAINING ──────────────────────────────────────
training:
  model_type: "xgboost" # or: "random_forest", "logistic_regression", etc.
  early_stopping_rounds: 10
  eval_metric: "logloss"
  n_estimators: 500
  learning_rate: 0.03
  max_depth: 6
  regularization:
    alpha: 0.1
    lambda: 1.0
  tune: true
  hyperparam_search:
    method: "optuna" # or: grid, random, hyperopt
    trials: 50
    cv_folds: 5
    scoring: "roc_auc"

# ────────────────────── PHASE-7 · EVALUATION ────────────────────────────────────
evaluation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc
    - log_loss

# ────────────────────── PHASE-8 · PACKAGING ─────────────────────────────────────
packaging:
  format: "onnx"
  output_path: "artefacts/model.onnx"

# ────────────────────── PHASE-9 · DEPLOYMENT ────────────────────────────────────
deployment:
  registry_url: "https://my-model-registry.io"
  credentials_env: "REGISTRY_AUTH_TOKEN"
